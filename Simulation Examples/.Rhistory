mutate(prim = gsub("[A-Za-z]*([1-9][0-9]?)_.*", "\\1", occ),
sec = gsub(".*_[A-Za-z]*([1-9]).*", "\\1", occ)) %>%
select(-occ)
}else{
out <- tmp %>%
arrange(Index)
}
}
eh <- extract_fun("_Sec", "eh")
x
head(x)
wt <- extract_fun("Weight", "weight")
# Random walk to hole
# Anna Moeller
# 6/29/2015
# Load packages
library(circular)
# Creates random walk and tells you when it first falls in hole
walk.fn <- function(max.steps, bounds, xhole, yhole){
# make weibull distributed steps
steps <- rweibull(max.steps, 2, 1)
# make clustered turning angles
theta <- rwrappedcauchy(max.steps, mu = 0, rho = .8)
# cumulative angle (absolute orientation)
phi <- cumsum(theta)
# step length components
dX <- steps*cos(phi)
dY <- steps*sin(phi)
# actual X-Y values (starting at (0,0))
X <- cumsum(dX)
Y <- cumsum(dY)
# plot that puppy
#plot(X, Y, type="l")
# If it stayed on the map, look to see when it first hit the camera,
#  otherwise return 9999
# This will return a vector of: integer for "on map, in hole"
#                               NA for "on map, not in hole"
#                               9999 for "not on map"
if(min(X) >= min(bounds) &
max(X) <= max(bounds) &
min(Y) >= min(bounds) &
max(Y) <= max(bounds)){
xcam <- which(round(X) >= min(xhole) & round(X) <= max(xhole))
ycam <- which(round(Y) >= min(yhole) & round(Y) <= max(yhole))
xcam[min(which(xcam %in% ycam))]
} else {
9999
}
}
# Call function, reps times, for starting population drawn from Pois
#  or equal starting pop
reps <- 1000
#start.pop <- rpois(reps, 50)
start.pop <- rep(50, reps)
walk <- lapply(start.pop, replicate, walk.fn(max.steps = 500,
bounds = -80:80,
xhole = 10:20,
yhole = 10:20))
# Time to first event for each pop
# NA pops where no animals hit the camera
timetohole <- sapply(walk, min, na.rm = T)
timetohole[timetohole == 9999] <- NA
timetohole[timetohole == Inf] <- NA
# # Did any populations have no animals hit the hole?
# tmp <- lapply(walk, function(x){!any(!is.na(x))})
# any(tmp == T)
# Number of animals I actually sampled (stayed on the map) for each pop
xx <- lapply(walk, function(x) {sapply(x, function(y) y != 9999 | is.na(y))})
sampled.pop <- sapply(xx, sum)
# Plot it up
prob <- hist(timetohole, prob = T)
hist(timetohole, prob = T, xlab = "Time to First Capture",
main = "Histogram of Time to First Capture", xlim = c(0, 100))
# Get lambda
avgtime <- mean(timetohole, na.rm = T) # average time to event, = 1/lambda
lambda <- 1/avgtime # average number of events per unit time
# Throw on the exponential curve
x <- 1:max(prob$breaks) - 1
y <- dexp(x, lambda)
lines(y~x, col = "red")
library(R2jags)
install.packages("R2jags")
library(R2jags)
library(R2jags)
nSam <- 20 					# number of plots sampled
nCamera <- 4				# number of cameras per plot
TrueLambda <- c( 10, 5 )	# true lambda for high and low density
TrueBeta <- 1/TrueLambda
TrueBeta
photoTimes <- matrix( NA, 400, nCamera )
photoTimes
gmu <- matrix( NA, 400, nCamera )
gmu
LamCov <-rbinom(400,1,.5)
LamCov
?rbinom
for( i in 1:400 ){
photoTimes[i,] <- rexp( nCamera, TrueBeta[LamCov[i]+1] )
gmu[i,] <-rpois( nCamera, photoTimes[i,] )
}
photoTimes
gmu
sp.data = list(photoTimes=photoTimes,
LamCov=LamCov)
sp.data
sp.params = c("beta", "beta0", "beta1", "N")  # jags
#Specify the initial values   omegaGuess = runif(1, n/(n+nzeroes), 1) #
sp.inits = function() {
list(
x = rpois(400,2)
)
}
#Run the model and call the results after
fit.int = jags(sp.data, sp.inits, sp.params, "cam_jags.txt",
n.chains=1, n.iter=10000, n.burnin=1000, n.thin=1)
#Run the model and call the results after
fit.int = jags(sp.data, sp.inits, sp.params, "cam_jags.txt",
n.chains=1, n.iter=10000, n.burnin=1000, n.thin=1)
setwd("~/GitHub/Camera-trap-study/Sampling")
#Run the model and call the results after
fit.int = jags(sp.data, sp.inits, sp.params, "cam_jags.txt",
n.chains=1, n.iter=10000, n.burnin=1000, n.thin=1)
setwd("~/GitHub/Camera-trap-study/Simulation")
#Run the model and call the results after
fit.int = jags(sp.data, sp.inits, sp.params, "cam_jags.txt",
n.chains=1, n.iter=10000, n.burnin=1000, n.thin=1)
fit.int
hist(fit.int)
hist(fit.int$mu.vect)
hist(as.numeric(fit.int$mu.vect))
head(fit.int)
lapply(fit.int, head)
head(fit.int$data)
head(fit.int@data)
head(fit.int$mu.vect)
head(fit.int$BUGSoutput)
# 100 binomial data sets. Each with 100 trials. Each value is the number of successes we got
numtrials <- 100
prob <- 0.5
numdatasets <- 100
data <- rbinom(n = numdatasets, size = numtrials, prob = prob)
# Version 1: MLE
mle.fn <- function(data, numtrials, numdatasets){
# Estimate p-hat, using MLE
p_hat <- data/numtrials
# Calculate SE(p-hat) (estimate SD)
SE_p_hat <- sqrt((p_hat*(1-p_hat))/numtrials)
# calculate LCI, UCI
LCI <- p_hat - 1.96*SE_p_hat
UCI <- p_hat + 1.96*SE_p_hat
# calculate coverage (the number of datasets where the CI actually overlapped p)
coverage <- sum(LCI < prob & prob < UCI)/numdatasets
# Store everything in a list
out <- list(p_hat = p_hat,
SE_p_hat = SE_p_hat,
LCI = LCI,
UCI = UCI,
coverage = coverage)
}
# Version 2: Logistic transformation
transf.fn <- function(data, numtrials, numdatasets){
# p = logistic(theta)) = 1/(1 + exp(-theta))
# L[p|y, n] = p^y * (1-p)^(n-y)
# L[theta|y, n] = (1/(1 + exp(-theta)))^y * (1-(1/(1 + exp(-theta))))^(n-y)
# logL[theta|y, n]
logL <- function(data, numtrials, theta){
data*log(1/(1 + exp(-theta))) + (numtrials - data)*log(1-(1/(1 + exp(-theta))))
}
# optimize logL
tmp <- lapply(data, function(x){
optim(par = .5, fn = logL, data = x,
numtrials = numtrials, control = list(fnscale = -1))
})
theta_hat <- sapply(tmp, function(x){
x$par
})
# Calculate var(theta_hat)
### Is this right????? this would work for a proportion, which theta is not.
var_theta_hat <- (theta_hat * (1 - theta_hat))/numtrials
# Get back to p
p_hat <- 1/(1 + exp(-theta_hat))
#   # Calculate SE(p_hat|theta_hat) = SE(1/(1+exp(-theta_hat)))
#   SE_p_hat <- sqrt(((1/(1+exp(-theta_hat)))*(1-(1/(1+exp(-theta_hat)))))/numtrials)
# Calculate SE(p_hat) from Delta Method
### Is this supposed to be the second derivative??
SE_p_hat <- sqrt((exp(theta_hat)*(1-exp(theta_hat)))/(exp(theta_hat)+1)^3 *
var_theta_hat)
### First derivative, squared?
SE_p_hat <- sqrt(exp(2*theta_hat)/((exp(theta_hat) + 1)^4) * var_theta_hat)
### Neither of these work because some of the var_theta_hats are negative
# Calculate CIs from SE(p_hat)
LCI <- p_hat - 1.96*SE_p_hat
UCI <- p_hat + 1.96*SE_p_hat
# calculate coverage (the number of datasets where the CI actually overlapped p)
coverage <- sum(LCI < prob & prob < UCI)/numdatasets
# Store everything in a list
out <- list(p_hat = p_hat,
SE_p_hat = SE_p_hat,
LCI = LCI,
UCI = UCI,
coverage = coverage)
}
### This is definitely not right.
# Version 3: Profile likelihood
### It looks like it is for estimating multiple parameters at once
### How do I use this in this instance?
###########################################################################
# 100 binomial data sets. Each with 100 trials - this is the number of successes we got
numtrials <- 100
prob <- 0.5
numdatasets <- 100
data <- rbinom(n = numdatasets, size = numtrials, prob = prob)
# Call them all
mle <- mle.fn(data, numtrials, numdatasets)
mle
data <- rbinom(n = numdatasets, size = numtrials, prob = 0.5)
mle0.5 <- mle.fn(data, numtrials, numdatasets)
data <- rbinom(n = numdatasets, size = numtrials, prob = 0.9)
mle0.9 <- mle.fn(data, numtrials, numdatasets)
data <- rbinom(n = numdatasets, size = numtrials, prob = 0.98)
mle0.98 <- mle.fn(data, numtrials, numdatasets)
mle0.5
mle0.9
mle0.98
# Call them all
data0.5 <- rbinom(n = numdatasets, size = numtrials, prob = 0.5)
mle0.5 <- mle.fn(data0.5, numtrials, numdatasets)
mle0.5
data0.9 <- rbinom(n = numdatasets, size = numtrials, prob = 0.9)
mle0.9 <- mle.fn(data0.9, numtrials, numdatasets)
mle0.9
data0.98 <- rbinom(n = numdatasets, size = numtrials, prob = 0.98)
mle0.98 <- mle.fn(data0.98, numtrials, numdatasets)
mle0.98
library(Hmisc)
mle <- mle0.5
x1 <- which(mle$LCI < prob & prob < mle$UCI)
x2 <- which(!(mle$LCI < prob & prob < mle$UCI))
errbar(x = x1, y = mle$p_hat[x1], yplus = mle$UCI[x1], yminus = mle$LCI[x1],
xlab = "", ylab = "p-hat")
errbar(x = x2, y = mle$p_hat[x2], yplus = mle$UCI[x2], yminus = mle$LCI[x2],
col = "red", errbar.col = "red", add = T)
abline(a = prob, b = 0, col = "red")
data0.9
mle <- mle0.9
x1 <- which(mle$LCI < prob & prob < mle$UCI)
x2 <- which(!(mle$LCI < prob & prob < mle$UCI))
errbar(x = x1, y = mle$p_hat[x1], yplus = mle$UCI[x1], yminus = mle$LCI[x1],
xlab = "", ylab = "p-hat")
errbar(x = x2, y = mle$p_hat[x2], yplus = mle$UCI[x2], yminus = mle$LCI[x2],
col = "red", errbar.col = "red", add = T)
abline(a = prob, b = 0, col = "red")
mle <- mle0.5
x1 <- which(mle$LCI < prob & prob < mle$UCI)
x2 <- which(!(mle$LCI < prob & prob < mle$UCI))
errbar(x = x1, y = mle$p_hat[x1], yplus = mle$UCI[x1], yminus = mle$LCI[x1],
xlab = "", ylab = "p-hat")
errbar(x = x2, y = mle$p_hat[x2], yplus = mle$UCI[x2], yminus = mle$LCI[x2],
col = "red", errbar.col = "red", add = T)
abline(a = prob, b = 0, col = "red")
mle0.9
# Version 1: MLE
mle.fn <- function(data, numtrials, numdatasets){
# Estimate p-hat, using MLE
p_hat <- data/numtrials
# Calculate SE(p-hat) (estimate SD)
SE_p_hat <- sqrt((p_hat*(1-p_hat))/numtrials)
# calculate LCI, UCI
LCI <- p_hat - 1.96*SE_p_hat
UCI <- p_hat + 1.96*SE_p_hat
# calculate coverage (the number of datasets where the CI actually overlapped p)
coverage <- sum(LCI < prob & prob < UCI)/numdatasets
# Store everything in a list
out <- list(p_hat = p_hat,
SE_p_hat = SE_p_hat,
LCI = LCI,
UCI = UCI,
coverage = coverage)
}
# 100 binomial data sets. Each with 100 trials - this is the number of successes we got
numtrials <- 100
numdatasets <- 100
data0.5 <- rbinom(n = numdatasets, size = numtrials, prob = 0.5)
data0.9 <- rbinom(n = numdatasets, size = numtrials, prob = 0.9)
data0.98 <- rbinom(n = numdatasets, size = numtrials, prob = 0.98)
# Call them all
mle0.5 <- mle.fn(data0.5, numtrials, numdatasets)
mle0.9 <- mle.fn(data0.9, numtrials, numdatasets)
mle0.98 <- mle.fn(data0.98, numtrials, numdatasets)
# Version 1: MLE
mle.fn <- function(data, prob, numtrials, numdatasets){
# Estimate p-hat, using MLE
p_hat <- data/numtrials
# Calculate SE(p-hat) (estimate SD)
SE_p_hat <- sqrt((p_hat*(1-p_hat))/numtrials)
# calculate LCI, UCI
LCI <- p_hat - 1.96*SE_p_hat
UCI <- p_hat + 1.96*SE_p_hat
# calculate coverage (the number of datasets where the CI actually overlapped p)
coverage <- sum(LCI < prob & prob < UCI)/numdatasets
# Store everything in a list
out <- list(p_hat = p_hat,
SE_p_hat = SE_p_hat,
LCI = LCI,
UCI = UCI,
coverage = coverage)
}
# 100 binomial data sets. Each with 100 trials - this is the number of successes we got
numtrials <- 100
numdatasets <- 100
data0.5 <- rbinom(n = numdatasets, size = numtrials, prob = 0.5)
data0.9 <- rbinom(n = numdatasets, size = numtrials, prob = 0.9)
data0.98 <- rbinom(n = numdatasets, size = numtrials, prob = 0.98)
# Call them all
mle0.5 <- mle.fn(data0.5, prob = 0.5, numtrials, numdatasets)
mle0.9 <- mle.fn(data0.9, prob = 0.9, numtrials, numdatasets)
mle0.98 <- mle.fn(data0.98, prob = 0.98, numtrials, numdatasets)
mle0.98
mle <- mle0.98
x1 <- which(mle$LCI < prob & prob < mle$UCI)
x2 <- which(!(mle$LCI < prob & prob < mle$UCI))
errbar(x = x1, y = mle$p_hat[x1], yplus = mle$UCI[x1], yminus = mle$LCI[x1],
xlab = "", ylab = "p-hat")
errbar(x = x2, y = mle$p_hat[x2], yplus = mle$UCI[x2], yminus = mle$LCI[x2],
col = "red", errbar.col = "red", add = T)
abline(a = prob, b = 0, col = "red")
mle <- mle0.98
prob <- 0.98
x1 <- which(mle$LCI < prob & prob < mle$UCI)
x2 <- which(!(mle$LCI < prob & prob < mle$UCI))
errbar(x = x1, y = mle$p_hat[x1], yplus = mle$UCI[x1], yminus = mle$LCI[x1],
xlab = "", ylab = "p-hat")
errbar(x = x2, y = mle$p_hat[x2], yplus = mle$UCI[x2], yminus = mle$LCI[x2],
col = "red", errbar.col = "red", add = T)
abline(a = prob, b = 0, col = "red")
mle <- mle0.5
prob <- 0.5
x1 <- which(mle$LCI < prob & prob < mle$UCI)
x2 <- which(!(mle$LCI < prob & prob < mle$UCI))
errbar(x = x1, y = mle$p_hat[x1], yplus = mle$UCI[x1], yminus = mle$LCI[x1],
xlab = "", ylab = "p-hat")
errbar(x = x2, y = mle$p_hat[x2], yplus = mle$UCI[x2], yminus = mle$LCI[x2],
col = "red", errbar.col = "red", add = T)
abline(a = prob, b = 0, col = "red")
mle <- mle0.9
prob <- 0.9
x1 <- which(mle$LCI < prob & prob < mle$UCI)
x2 <- which(!(mle$LCI < prob & prob < mle$UCI))
errbar(x = x1, y = mle$p_hat[x1], yplus = mle$UCI[x1], yminus = mle$LCI[x1],
xlab = "", ylab = "p-hat")
errbar(x = x2, y = mle$p_hat[x2], yplus = mle$UCI[x2], yminus = mle$LCI[x2],
col = "red", errbar.col = "red", add = T)
abline(a = prob, b = 0, col = "red")
mle <- mle0.98
prob <- 0.98
x1 <- which(mle$LCI < prob & prob < mle$UCI)
x2 <- which(!(mle$LCI < prob & prob < mle$UCI))
errbar(x = x1, y = mle$p_hat[x1], yplus = mle$UCI[x1], yminus = mle$LCI[x1],
xlab = "", ylab = "p-hat")
errbar(x = x2, y = mle$p_hat[x2], yplus = mle$UCI[x2], yminus = mle$LCI[x2],
col = "red", errbar.col = "red", add = T)
abline(a = prob, b = 0, col = "red")
plot.fn <- function(mle, prob){
x1 <- which(mle$LCI < prob & prob < mle$UCI)
x2 <- which(!(mle$LCI < prob & prob < mle$UCI))
plot <- errbar(x = x1, y = mle$p_hat[x1], yplus = mle$UCI[x1], yminus = mle$LCI[x1],
xlab = "", ylab = "p-hat")
plot <- errbar(x = x2, y = mle$p_hat[x2], yplus = mle$UCI[x2], yminus = mle$LCI[x2],
col = "red", errbar.col = "red", add = T)
abline(a = prob, b = 0, col = "red")
return(plot)
}
plot.fn(mle0.5, 0.5)
numtrials <- 100
numdatasets <- 100
data0.5 <- rbinom(n = numdatasets, size = numtrials, prob = 0.5)
# logL[theta|y, n]
logL <- function(data, numtrials, theta){
data*log(1/(1 + exp(-theta))) + (numtrials - data)*log(1-(1/(1 + exp(-theta))))
}
# optimize logL
tmp <- lapply(data, function(x){
optim(par = .5, fn = logL, data = x,
numtrials = numtrials, control = list(fnscale = -1), hessian = T)
})
theta_hat <- sapply(tmp, function(x){
x$par
})
# Get back to p
p_hat <- 1/(1 + exp(-theta_hat))
data <- rbinom(n = numdatasets, size = numtrials, prob = 0.5)
# logL[theta|y, n]
logL <- function(data, numtrials, theta){
data*log(1/(1 + exp(-theta))) + (numtrials - data)*log(1-(1/(1 + exp(-theta))))
}
# optimize logL
tmp <- lapply(data, function(x){
optim(par = .5, fn = logL, data = x,
numtrials = numtrials, control = list(fnscale = -1), hessian = T)
})
theta_hat <- sapply(tmp, function(x){
x$par
})
# Get back to p
p_hat <- 1/(1 + exp(-theta_hat))
p_hat
theta_hat
tmp
var_theta_hat <- -1/tmp$hessian
SE_p_hat <- sqrt(exp(2*theta_hat)/((exp(theta_hat) + 1)^4) * var_theta_hat)
SE_p_hat
SE_p_hat <- exp(theta_hat)/((exp(theta_hat) + 1)^2) * sqrt(var_theta_hat)
SE_p_hat
var_theta_hat <- -1/tmp$hessian
SE_p_hat <- exp(theta_hat)/((exp(theta_hat) + 1)^2) * sqrt(var_theta_hat)
var_theta_hat <- -1/tmp$hessian
SE_p_hat
theta_hat
var_theta_hat
var_theta_hat <- -1/tmp$hessian
var_theta_hat
tmp$hessian
tmp
var_theta_hat <- lapply(tmp, function(x){
-1/x$hessian
}
)
var_theta_hat
var_theta_hat <- sapply(tmp, function(x){
-1/x$hessian
})
var_theta_hat
SE_p_hat <- exp(theta_hat)/((exp(theta_hat) + 1)^2) * sqrt(var_theta_hat)
SE_p_hat
# Calculate CIs from SE(p_hat)
LCI <- p_hat - 1.96*SE_p_hat
UCI <- p_hat + 1.96*SE_p_hat
# calculate coverage (the number of datasets where the CI actually overlapped p)
coverage <- sum(LCI < prob & prob < UCI)/numdatasets
voerage
coverage
LCI
UCI
prob
prob <- 0.5
coverage <- sum(LCI < prob & prob < UCI)/numdatasets
coverage
# logL[p|y, n]
logL <- function(data, numtrials, p){
data*log(p) + (numtrials - data)*log(p)
}
# optimize logL
tmp <- lapply(data, function(x){
optim(par = .5, fn = logL, data = x,
numtrials = numtrials, control = list(fnscale = -1), hessian = T)
})
tmp
# logL[p|y, n]
logL <- function(data, numtrials, p){
data*log(p) + (numtrials - data)*log(1-p)
}
# optimize logL
tmp <- lapply(data, function(x){
optim(par = .5, fn = logL, data = x,
numtrials = numtrials, control = list(fnscale = -1), hessian = T)
})
tmp
p_hat <- sapply(tmp, function(x){
x$par
})
p_hat
tmp
logLval <- sapply(tmp, function(x){
x$value
})
logLval
?polyroot
?root
??root
# value of logL(p_hat)
logLval <- sapply(tmp, function(x){
x$value
})
# Solve
tosolve <- function(data, numtrials, p){
-2*(data*log(p) + (numtrials - data)*log(1-p)) + 2*logLval - 1.92
}
# Find roots using uniroot
uniroot(tosolve, c(0,1))
uniroot(f = tosolve, interval = 0:1)
uniroot(f = tosolve, interval = 0:1, data = data, numtrials = numtrials)
uniroot(f = tosolve, interval = c(0, 1), data = data, numtrials = numtrials)
tosolve <- function(data, numtrials, p){
-2*(data*log(p) + (numtrials - data)*log(1-p)) + 2 - 1.92
}
# Find roots using uniroot
uniroot(f = tosolve, interval = c(0, 1), data = data, numtrials = numtrials)
tosolve(data, numtrials, 0.1)
tosolve(data, numtrials, 0.5)
tosolve(data, numtrials, 0.6)
uniroot(f = tosolve, interval = c(0, 1), data = data[1], numtrials = numtrials)
logLval
# Solve
tosolve <- function(data, numtrials, x){
-2*(data*log(x) + (numtrials - data)*log(1-x)) + 2*logLval - 1.92
}
curve(tosolve, from = 0, to = 100, n = 101)
curve(expr = -2*(data*log(x) + (numtrials - data)*log(1-x)) + 2*logLval - 1.92), from = 0, to = 1, n = 101
curve(expr = -2*(data*log(x) + (numtrials - data)*log(1-x)) +
2*logLval - 1.92), from = 0, to = 1, n = 101)
curve(expr = -2*(data*log(x) + (numtrials - data)*log(1-x)) +
2*logLval - 1.92, from = 0, to = 1, n = 101)
